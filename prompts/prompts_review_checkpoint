# Review Checkpoint Guidelines

## Overview
This document defines the review checkpoints for each section in the incremental PDF compilation workflow. At each checkpoint, the AI must STOP and wait for user approval before proceeding.

## General Review Protocol

### STOP Message Format
```
ğŸ“‹ REVIEW CHECKPOINT REACHED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Section: [Section Name]
Version: v[n]
File: [filename]_v[n].pdf
Status: Compiled successfully âœ…
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Please review the PDF and check the following items.
Then respond with:
â€¢ "approve" - to continue to the next section
â€¢ "revise [specific changes]" - to make changes

[Section-specific checklist and questions below]
```

## Section-Specific Checklists

### IMPORTANT: Section Checklist in PDF
**Each section PDF will include a comprehensive checklist at the end. This checklist will appear both as LaTeX comments in the .tex file AND as a visible section in the PDF for easy review.**

**NOTE FOR FINAL ASSEMBLY**: These checklists are for individual section review only. When compiling the final main.pdf, these checklist sections will NOT be included - only the actual content of each section is used in main.tex.

### How Checklists Are Excluded from Final PDF

**IMPORTANT**: The checklists must remain in the original section .tex files for review PDFs. For the final main.pdf, use ONE of these methods:

**CRITICAL NOTE**: Reference Verification Summary sections that appear in review checklists (especially in introduction sections) MUST also be excluded from the final main.pdf. These summaries are ONLY for review purposes to help users verify downloaded papers.

1. **Method A - Clean Files**: Create clean versions without checklists
   ```bash
   # Example: Create introduction_clean.tex from introduction.tex
   # Copy content up to (but not including) the checklist section
   ```

2. **Method B - Marker Comments**: Add a special marker before checklists
   ```latex
   %% BEGIN REVIEW CHECKLIST - DO NOT INCLUDE IN FINAL PDF
   \newpage
   \section*{========== SECTION REVIEW CHECKLIST ==========}
   [checklist content...]
   %% END REVIEW CHECKLIST
   ```
   Then in main.tex, use custom input commands that stop at the marker.

3. **Method C - Manual Extraction**: When creating main.tex, manually extract only the content portions, excluding everything after the checklist marker.

**CRITICAL**: DO NOT delete checklists from the original .tex files!

### 1. Introduction Section Review

**Checklist:**
- [ ] Problem statement is accurately captured
- [ ] Literature review covers relevant papers
- [ ] All citations have corresponding PDFs in output/papers/
- [ ] Research gap is clearly identified
- [ ] Proposed approach is well motivated
- [ ] Writing flows logically
- [ ] No grammatical errors or typos

**Specific Questions:**
1. Does the introduction adequately motivate why this problem is important?
2. Are there any key papers or methods that should be added to the literature review?
3. Is the research gap clearly articulated?
4. Does the proposed approach align with what you want to implement?

**What to Look For:**
- Verify all 5 Ps are covered (for competitions)
- Check that cited papers actually exist
- Ensure no hallucinated references
- Confirm problem restatement matches original

**Automated Verification Summary:**
The introduction PDF will include an automated verification summary showing:
- Total papers attempted and verified
- Verification success rate (should be >95%)
- Number of papers automatically excluded
- All verification decisions were made automatically
- Full details available in output/verification_db.json

**Example Checklist in LaTeX (added to .tex file):**
```latex
% At the end of introduction.tex, AFTER all main content:

%% BEGIN REVIEW CHECKLIST - DO NOT INCLUDE IN FINAL PDF
\newpage
\section*{========== SECTION REVIEW CHECKLIST ==========}
\subsection*{Introduction Section Checklist}

\textbf{Review Items:}
\begin{itemize}
    \item Problem statement is accurately captured
    \item Literature review covers relevant papers
    \item All citations have corresponding PDFs in output/papers/
    \item Research gap is clearly identified
    \item Proposed approach is well motivated
    \item Writing flows logically
    \item No grammatical errors or typos
\end{itemize}

\textbf{Specific Questions:}
\begin{enumerate}
    \item Does the introduction adequately motivate why the [specific problem] is important?
    \item Are there any key papers or methods that should be added to the literature review?
    \item Is the research gap clearly articulated?
    \item Does the proposed approach align with what you want to implement?
\end{enumerate}

\textbf{Key Updates Made:}
\begin{itemize}
    \item Fixed any citation issues
    \item Used [template name] template
    \item Included [X] citations covering [topics]
    \item Focused on [specific aspects]
\end{itemize}

\textbf{Current Status:}
\begin{itemize}
    \item [X]-page PDF with proper bibliography
    \item All citations verified to have corresponding papers
    \item Follows [competition/journal] format
\end{itemize}

\textbf{Reference Verification Summary:} % FOR REVIEW ONLY - NOT IN FINAL PDF
\begin{itemize}
    \item Total papers attempted: [X]
    \item Successfully verified: [Y] ([Z]\%)
    \item Verification decisions: All automatic
    \item Full details: output/verification\_db.json
\end{itemize}
%% END REVIEW CHECKLIST
```

**Example Checklist in PDF:**
The PDF will include a section at the end formatted like:
```
========== SECTION REVIEW CHECKLIST ==========
Introduction Section Checklist:

Review Items:
- Problem statement is accurately captured
- Literature review covers relevant papers
- All citations have corresponding PDFs in output/papers/
- Research gap is clearly identified
- Proposed approach is well motivated
- Writing flows logically
- No grammatical errors or typos

Specific Questions:
1. Does the introduction adequately motivate why the [specific problem]
   is important?
2. Are there any key papers or methods that should be added to the literature
   review?
3. Is the research gap clearly articulated?
4. Does the proposed approach align with what you want to implement?

Key Updates Made:
- Fixed any citation issues
- Used [template name] template
- Included [X] citations covering [topics]
- Focused on [specific aspects]

Current Status:
- [X]-page PDF with proper bibliography
- All citations verified to have corresponding papers
- Follows [competition/journal] format

Reference Verification Summary: (FOR REVIEW ONLY - NOT IN FINAL PDF)
- Total papers attempted: [X]
- Successfully verified: [Y] ([Z]%)
- Automatically excluded: [N]
- All papers verified for title match, author match, and domain relevance
- Verification details in output/verification_db.json
========== END SECTION REVIEW CHECKLIST ==========
```

**LaTeX Format for .tex File:**
```latex
%% ========== SECTION REVIEW CHECKLIST ==========
%% Introduction Section Checklist:
%% 
%% Review Items:
%% - Problem statement is accurately captured
%% - Literature review covers relevant papers
%% - All citations have corresponding PDFs in output/papers/
%% - Research gap is clearly identified
%% - Proposed approach is well motivated
%% - Writing flows logically
%% - No grammatical errors or typos
%% 
%% Specific Questions:
%% 1. Does the introduction adequately motivate why the [specific problem]
%%    is important?
%% 2. Are there any key papers or methods that should be added to the literature
%%    review?
%% 3. Is the research gap clearly articulated?
%% 4. Does the proposed approach align with what you want to implement?
%% 
%% Key Updates Made:
%% - Fixed any citation issues
%% - Used [template name] template
%% - Included [X] citations covering [topics]
%% - Focused on [specific aspects]
%% 
%% Current Status:
%% - [X]-page PDF with proper bibliography
%% - All citations verified to have corresponding papers
%% - Follows [competition/journal] format
%% ========== END SECTION REVIEW CHECKLIST ==========
```

### 2. Infographic Review

**Checklist:**
- [ ] Infographic clearly visualizes the problem/solution
- [ ] Design is professional and readable
- [ ] Key concepts are highlighted
- [ ] Visual hierarchy is clear
- [ ] Colors follow the specified color scheme
- [ ] File saved as PNG in correct location

**Specific Questions:**
1. Does the infographic effectively communicate the core concepts?
2. Is anything important missing from the visualization?
3. Are the visual metaphors appropriate and clear?

### 3. Methods Section Review

**Checklist:**
- [ ] All models/algorithms are clearly explained
- [ ] Mathematical notation is consistent
- [ ] Symbol table is complete
- [ ] Assumptions are explicitly stated
- [ ] Pseudocode matches planned implementation
- [ ] Workflow diagram is included
- [ ] Sensitivity analysis plan is appropriate

**Specific Questions:**
1. Are the mathematical models appropriate for solving the problem?
2. Do the algorithms have clear termination conditions?
3. Are there any missing parameters or assumptions?
4. Is the methodology reproducible based on this description?

**Code Review Note:**
After methods approval, Python scripts will be presented directly (not in PDF form).

### 4. Code Review (Special)

**Display Format:**
```
ğŸ“‚ Code Files Ready for Review
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Files in output/codes/:
1. model_optimization.py (Main solver)
2. data_preprocessing.py (Data preparation)
3. visualization.py (Figure generation)
4. sensitivity_analysis.py (Parameter testing)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Review each file for:
â€¢ Correctness of implementation
â€¢ Alignment with methods section
â€¢ Code quality and documentation
â€¢ Test coverage

Respond with:
â€¢ "approve" - to proceed to execution instructions
â€¢ "revise [file] [changes]" - to modify
```

**Code Checklist:**
- [ ] Implementation matches methods description
- [ ] Functions are well-documented
- [ ] Input/output specifications are clear
- [ ] Error handling is appropriate
- [ ] Test mode is implemented
- [ ] Code follows Python best practices

### 5. Code Execution Handoff (Special)

**Display Format:**
```
ğŸ–¥ï¸ CODE EXECUTION HANDOFF
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Scripts have been tested and are ready for full execution.
Due to computational requirements, you'll need to run them on your system.

Execution Instructions:
[Detailed instructions provided]

Estimated Runtime: [X hours total]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Please execute the scripts following the instructions above.
When complete, respond with:
â€¢ "execution complete" - All outputs generated successfully
â€¢ "execution failed: [error]" - If you encounter issues
```

**Pre-Execution Checklist:**
- [ ] All scripts tested successfully in test mode
- [ ] Execution instructions are clear
- [ ] Runtime estimates provided
- [ ] Input/output paths specified
- [ ] Required packages listed

**After Execution:**
- [ ] All expected figures generated in output/figures/
- [ ] All data files created in output/data/
- [ ] No error messages in execution
- [ ] Outputs match expected format

### 6. Results Section Review

**Checklist:**
- [ ] All figures are clear and properly labeled
- [ ] Tables are formatted correctly
- [ ] Captions are descriptive
- [ ] Results align with methods
- [ ] Statistical significance is reported (if applicable)
- [ ] Comparisons are fair and complete
- [ ] Discussion interprets results appropriately

**Specific Questions:**
1. Do the results support your hypotheses?
2. Are there any surprising findings that need more investigation?
3. Should any additional analyses be performed?
4. Are the visualizations effective in conveying the findings?

**Special Attention:**
- Verify figure quality (resolution, readability)
- Check table formatting
- Ensure all referenced figures/tables exist

### 7. Conclusions Section Review

**Checklist:**
- [ ] Key findings are summarized
- [ ] Contributions are clearly stated
- [ ] Limitations are acknowledged
- [ ] Future work is proposed
- [ ] Conclusions follow from results
- [ ] No new information introduced

**Specific Questions:**
1. Do the conclusions accurately reflect the work done?
2. Are the limitations fairly presented?
3. Is the future work section realistic and valuable?

### 7. Competition-Specific Sections

#### Summary (Executive Summary)
**Checklist:**
- [ ] Within word limit (550 words)
- [ ] Covers all major points
- [ ] Can stand alone
- [ ] Compelling and clear

#### Letter to Decision Makers
**Checklist:**
- [ ] Within word limit (600-700 words)
- [ ] Appropriate tone
- [ ] Clear recommendations
- [ ] Actionable insights

### 8. Journal-Specific Sections

#### Abstract
**Checklist:**
- [ ] Within journal word limit
- [ ] Includes all required elements
- [ ] No citations (if journal requires)
- [ ] Clear and concise

### 9. Appendices Review

**Checklist:**
- [ ] AI usage report is complete
- [ ] Code documentation is included
- [ ] Supplementary materials are organized
- [ ] All appendices are referenced in main text

## Handling Revisions

### Revision Response Format
When user requests revisions, acknowledge with:
```
ğŸ“ Revision Request Received
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Section: [Section Name]
Current Version: v[n]
Next Version: v[n+1]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Changes requested:
1. [Change 1]
2. [Change 2]
...

Working on revisions...
```

### Post-Revision
After making changes:
1. Create new version (v2, v3, etc.)
2. Log changes in version_log.txt
3. Recompile PDF
4. Present same review checkpoint again

## Quality Metrics

Track these metrics across sections:
- Number of revisions per section
- Common revision themes
- Compilation success rate
- Time spent per section

## Special Considerations

### Large Sections
For sections that might exceed 10 pages:
- Warn user about length
- Offer to split if appropriate
- Ensure PDF is still manageable

### Dependencies
Some sections depend on others:
- Results depends on code execution
- Conclusions depends on results
- Flag any forward references

### Template Compliance

## Section-by-Section Double-Checks

After completing each section, perform these comprehensive checks:

### 1. Post-Introduction Check
- âœ“ All citations have verified PDFs
- âœ“ Problem correctly restated
- âœ“ Literature review matches downloaded papers
- âœ“ **CRITICAL: Every sentence is supported by specific literature source or evidence**
- âœ“ Document which LaTeX packages this section's content requires
- âœ“ Reference Verification Summary included (for review PDF only)

### 2. Post-Methods Check
- âœ“ All equations properly formatted
- âœ“ Code in output/codes/ passes test mode
- âœ“ **CRITICAL: If code contains model training, STOP and handoff to user**
- âœ“ **CRITICAL: Run validation_checklist.py before handoff**
- âœ“ **CRITICAL: Generate execution_plan.json with dependencies**
- âœ“ **CRITICAL: Create EXECUTION_INSTRUCTIONS.md for user**
- âœ“ Pseudo-code matches implementation
- âœ“ **CRITICAL: Every claim is backed by mathematical derivation or cited source**
- âœ“ **CRITICAL: Code implementation MUST reflect actual methods described in tex file**
- âœ“ **CRITICAL: No mismatch between mathematical formulas and code algorithms**
- âœ“ Document which LaTeX packages this section's content requires
- âœ“ Verify these packages will be available in final compilation

### 3. Post-Results Check
- âœ“ All figures exist in output/figures/
- âœ“ All figures with boxes passed validation (no overlaps)
- âœ“ All tables have source data in output/data/
- âœ“ Results are reproducible from provided code
- âœ“ Box validation reports saved for all diagrams
- âœ“ **CRITICAL: Every result is traceable to actual computational output**
- âœ“ Document which LaTeX packages this section's content requires
- âœ“ Verify these packages will be available in final compilation

### 4. Post-Conclusions Check
- âœ“ Conclusions follow logically from results
- âœ“ No new claims introduced without support
- âœ“ Future work is feasible and relevant
- âœ“ All recommendations are evidence-based

### 5. Post-Summary/Abstract Check
- âœ“ Word count within limits
- âœ“ Key contributions clearly stated
- âœ“ Results accurately summarized
- âœ“ No claims beyond what's in the paper
Always verify:
- Section follows template style
- Citations use correct format
- Formatting matches competition/journal requirements

## Emergency Procedures

### If Compilation Fails
1. Show detailed error message
2. Attempt automatic fix
3. If still failing, create plain text version for review
4. Ask user for guidance

### If User is Unresponsive
After presenting checkpoint:
1. Wait indefinitely (do not timeout)
2. Do NOT proceed without approval
3. User may return hours/days later

## Review Best Practices

1. **Be Specific**: Point out exact issues
2. **Be Constructive**: Suggest improvements
3. **Be Thorough**: Check all aspects
4. **Be Patient**: Allow time for careful review
5. **Be Clear**: Make approval process obvious

## Example Review Interaction

```
AI: ğŸ“‹ REVIEW CHECKPOINT REACHED
    [Details and checklist...]
    
User: The literature review seems incomplete. Please add papers about 
      neural networks applications to this problem. Also, the third 
      paragraph has some grammatical errors.

AI: ğŸ“ Revision Request Received
    [Makes changes, recompiles...]
    
AI: ğŸ“‹ REVIEW CHECKPOINT REACHED
    Section: Introduction
    Version: v2
    [Updated content...]
    
User: approve

AI: âœ… Introduction section approved!
    Moving to next phase: Infographic Design...
```