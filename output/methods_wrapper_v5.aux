\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{vahab2022physics,kapoor2023physics}
\citation{hu2024hutchinson}
\citation{brunton2024machine}
\citation{wang2021understanding,krishnapriyan2021characterizing}
\citation{han1999dynamics}
\citation{raissi2019physics}
\citation{wong2022learning}
\@writefile{toc}{\contentsline {section}{\numberline {1}Methodology}{1}{section.1}\protected@file@percent }
\newlabel{sec:method}{{1}{1}{Methodology}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Theoretical Framework: Addressing the Ultra-Precision Challenge}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Assumptions and Justification}{1}{subsection.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Symbol Descriptions\relax }}{2}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:symbols}{{1}{2}{Symbol Descriptions\relax }{table.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Notations}{2}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Hybrid Fourier-Neural Architecture: The Breakthrough Design}{2}{subsection.1.4}\protected@file@percent }
\newlabel{eq:hybrid_solution}{{1}{2}{Hybrid Fourier-Neural Architecture: The Breakthrough Design}{equation.1.1}{}}
\citation{mcclenny2023self}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Physics-Informed Loss Function with Adaptive Weighting}{4}{subsection.1.5}\protected@file@percent }
\newlabel{eq:euler_bernoulli}{{7}{4}{Physics-Informed Loss Function with Adaptive Weighting}{equation.1.7}{}}
\citation{wang2021understanding,mcclenny2020self}
\citation{penwarden2023unified}
\citation{kingma2014adam}
\citation{liu1989limited}
\citation{jagtap2020conservative}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Two-Phase Optimization Strategy: Breaking the Precision Barrier}{5}{subsection.1.6}\protected@file@percent }
\citation{psaros2023uncertainty}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Ultra-Precision PINN Training Algorithm\relax }}{6}{algorithm.1}\protected@file@percent }
\newlabel{alg:training}{{1}{6}{Ultra-Precision PINN Training Algorithm\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7}GPU-Efficient Implementation}{6}{subsection.1.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8}Sensitivity Analysis and Harmonic Discovery}{6}{subsection.1.8}\protected@file@percent }
\bibstyle{apalike}
\bibdata{methods_refs}
\bibcite{brunton2024machine}{{1}{2024}{{Brunton and Kutz}}{{}}}
\bibcite{han1999dynamics}{{2}{1999}{{Han et~al.}}{{}}}
\bibcite{hu2024hutchinson}{{3}{2024}{{Hu et~al.}}{{}}}
\bibcite{jagtap2020conservative}{{4}{2020}{{Jagtap et~al.}}{{}}}
\bibcite{kapoor2023physics}{{5}{2023}{{Kapoor et~al.}}{{}}}
\bibcite{kingma2014adam}{{6}{2015}{{Kingma and Ba}}{{}}}
\bibcite{krishnapriyan2021characterizing}{{7}{2021}{{Krishnapriyan et~al.}}{{}}}
\bibcite{liu1989limited}{{8}{1989}{{Liu and Nocedal}}{{}}}
\bibcite{mcclenny2020self}{{9}{2020}{{McClenny and Braga-Neto}}{{}}}
\bibcite{mcclenny2023self}{{10}{2023}{{McClenny and Braga-Neto}}{{}}}
\bibcite{penwarden2023unified}{{11}{2023}{{Penwarden et~al.}}{{}}}
\bibcite{psaros2023uncertainty}{{12}{2023}{{Psaros et~al.}}{{}}}
\bibcite{raissi2019physics}{{13}{2019}{{Raissi et~al.}}{{}}}
\bibcite{vahab2022physics}{{14}{2022}{{Vahab et~al.}}{{}}}
\bibcite{wang2021understanding}{{15}{2021}{{Wang et~al.}}{{}}}
\bibcite{wong2022learning}{{16}{2024}{{Wong et~al.}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Hybrid Fourier-PINN architecture for the Euler-Bernoulli beam equation showing both forward pass (solid arrows) and backward propagation (dashed arrows). The architecture combines a truncated Fourier series expansion (10 harmonics) with a 7-layer deep neural network (2→128→128→64→32→16→8→1 neurons). The Fourier coefficients $A_n$ and $B_n$ are learnable parameters trained through backpropagation, not outputs from the neural network. Boundary conditions are enforced through multiplication with $\qopname  \relax o{sin}(\pi x/L)$. The two-phase optimization strategy achieves L2 error of $1.94 \times 10^{-7}$.\relax }}{9}{figure.caption.2}\protected@file@percent }
\newlabel{fig:architecture}{{1}{9}{Hybrid Fourier-PINN architecture for the Euler-Bernoulli beam equation showing both forward pass (solid arrows) and backward propagation (dashed arrows). The architecture combines a truncated Fourier series expansion (10 harmonics) with a 7-layer deep neural network (2→128→128→64→32→16→8→1 neurons). The Fourier coefficients $A_n$ and $B_n$ are learnable parameters trained through backpropagation, not outputs from the neural network. Boundary conditions are enforced through multiplication with $\sin (\pi x/L)$. The two-phase optimization strategy achieves L2 error of $1.94 \times 10^{-7}$.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Training workflow and optimization strategy for the ultra-precision PINN. The methodology employs a two-phase approach: initial Adam optimization for rapid convergence followed by L-BFGS refinement for ultra-high precision. Dynamic memory management and adaptive weight balancing ensure stable training throughout both phases.\relax }}{10}{figure.caption.3}\protected@file@percent }
\newlabel{fig:workflow}{{2}{10}{Training workflow and optimization strategy for the ultra-precision PINN. The methodology employs a two-phase approach: initial Adam optimization for rapid convergence followed by L-BFGS refinement for ultra-high precision. Dynamic memory management and adaptive weight balancing ensure stable training throughout both phases.\relax }{figure.caption.3}{}}
\gdef \@abspage@last{10}
